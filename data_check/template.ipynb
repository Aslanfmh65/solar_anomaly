{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "import difflib \n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the data\n",
    "# col_to_drop = ['weather','date_time','daily_mape','mape_std']\n",
    "# col_to_drop = []\n",
    "\n",
    "# east_data = east_data[(east_data.weather =='sunny')]\n",
    "# west_data = west_data[(west_data.weather =='sunny')]\n",
    "# lower_data = lower_data[(lower_data.weather =='sunny')]\n",
    "\n",
    "# east_data = east_data[east_data.weather != 'sunny'].drop(col_to_drop,axis=1)\n",
    "# west_data = west_data[west_data.condition == 'normal'].drop(col_to_drop,axis=1)\n",
    "# lower_data = lower_data[lower_data.condition == 'normal'].drop(col_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define dataset\n",
    "# dataset = east_data\n",
    "# daily_mape = process.daily_dict(dataset,'daily_mape')\n",
    "# daily_weather = process.daily_dict(dataset,'weather')\n",
    "# daily_std = process.daily_dict(dataset,'mape_std')\n",
    "# daily_empty = process.daily_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Daily MAPE histogram\n",
    "# visual.histogram(list(east_data['weather'].values),\"east_hist\",False,500)\n",
    "# visual.histogram(list(west_data['daily_mape'].values),\"west_hist\",True,500)\n",
    "# visual.histogram(list(lower_data['daily_mape'].values),\"south_hist\",True,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Weather Pie Chart\n",
    "# weathers = []\n",
    "# for _, i in daily_weather.items():\n",
    "#     weathers.append(i)\n",
    "# visual.pie_chart(weathers,\"Weather Condition - 860 Days\",True,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict power output by regression and reture the predictions for each panel\n",
    "# res1,pred1 = model.model_predict(east_data,True)\n",
    "# res2,pred2 = model.model_predict(west_data,True)\n",
    "# res3,pred3 = model.model_predict(lower_data,True)\n",
    "\n",
    "# # Convert predictions into DataFrame format for each panel\n",
    "# df = pd.DataFrame((pred1[0]))\n",
    "# for i in range(1,len(pred1)):\n",
    "#     df[str(i)] = pd.DataFrame(pred1[i])\n",
    "    \n",
    "# # Save the predictions \n",
    "# export_csv = df.to_csv (\"east_normal_pred.csv\", index = False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually calculate MAPE and find distribution\n",
    "# dataset = pd.read_csv('east_normal_gt_pred.csv')\n",
    "\n",
    "# n = len(dataset.columns)//2\n",
    "# errors = {'MAPE':[],'MSE':[],'MAE':[]}\n",
    "\n",
    "# error_high = []\n",
    "\n",
    "# for i in range(n):\n",
    "#     col = 'panel_'+str(i+1)\n",
    "#     gt = dataset[col+'_power']\n",
    "#     pred = dataset[col+'_predict']\n",
    "#     error = []\n",
    "#     high_error_count = 0\n",
    "    \n",
    "#     for j in range(len(gt)):\n",
    "#         err = np.abs(gt[j]-pred[j])/gt[j]\n",
    "#         if err == np.float64('inf') or err == np.float64('nan'):\n",
    "#             continue\n",
    "#         error.append(np.abs(gt[j]-pred[j])/gt[j])\n",
    "        \n",
    "#         if err > 0.05:\n",
    "#             high_error_count += 1\n",
    "#     error_high.append(high_error_count)\n",
    "\n",
    "#     errors['MAPE'].append(np.nansum(error)/len(error)*100)\n",
    "#     errors['MSE'].append(mean_squared_error(gt,pred))\n",
    "#     errors['MAE'].append(mean_absolute_error(gt,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for day in set(wrong_date):\n",
    "#     data = daily_data[day].drop(['weather','daily_mape','mape_std','condition'],axis=1)\n",
    "#     mape = round(df[df['date']==day]['daily_mape'],2)\n",
    "#     std = round(df[df['date']==day]['mape_std'],2)\n",
    "#     corr = round(df[df['date']==day]['correlation'],3)\n",
    "#     weather = df[df['date']==day]['weather']\n",
    "    \n",
    "# #     title = \"MAPE \"+str(mape)+\"; STD \"+str(std)+\"; corr \"+str(corr)+\"; weather \" + weather\n",
    "#     title = \"MAPE \"+str(mape)\n",
    "#     visual.raw_data_plot(data,title,save=False,resolution=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miss_data = ['20190829','20190930','20190905','20190906','20190917','20190919','20191010','20191017',\n",
    "#              '20191031','20191120','20191125','20191213','20190223','20191012','20180516','20180820',\n",
    "#              '20190510','20170920','20190824','20190827','20180829']\n",
    "\n",
    "# for miss in miss_data:\n",
    "#     data = raw_data[miss].drop(['weather','daily_mape','mape_std','condition'],axis=1)\n",
    "#     visual.raw_data_plot(data,miss)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new dataframe from old one\n",
    "# df = pd.DataFrame()\n",
    "# for day in raw_data:\n",
    "#     data = raw_data[day]\n",
    "#     data[\"date\"] = day\n",
    "#     df = pd.concat([df,data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def create_dataset(data):\n",
    "        \n",
    "    dataX, dataY = [],[]\n",
    "    for i in range(len(data)):\n",
    "        dataX.append(data[i][:-1])\n",
    "        dataY.append(int(data[i][-1])) \n",
    "            \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def random_forest_class(dataset):\n",
    "    \n",
    "    date = dataset['date'].values\n",
    "    dataset = dataset.drop(['date'],axis=1).values\n",
    "        \n",
    "    X, Y = create_dataset(dataset)\n",
    "    cvscores = []\n",
    "    cm = []\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "        \n",
    "    for train_index, test_index in kfold.split(X, Y):\n",
    "            \n",
    "        X_train = X[train_index]\n",
    "        y_train = Y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = Y[test_index]\n",
    "        test_date = date[test_index]\n",
    "        \n",
    "        rf_model = RandomForestClassifier(max_depth=10, random_state=1).fit(X_train, y_train)\n",
    "        rf_prediction = rf_model.predict(X_test)\n",
    "        cvscores.append(accuracy_score(y_test, rf_prediction)*100)\n",
    "        cm.append(confusion_matrix(y_test, rf_prediction))\n",
    "        \n",
    "    return [cvscores, cm, rf_model,X_test,y_test,test_date]\n",
    "\n",
    "def confusion_matrix_plot(cm,acc,save=False):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    sns.set(font_scale=1)\n",
    "    sns.heatmap(cm, annot=True,fmt='g',annot_kws={\"size\": 15},cmap=\"Blues\", square=True, cbar=False)\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Prediction',fontsize=18)\n",
    "    ax.set_ylabel('Ground Truth',fontsize=18)\n",
    "    title_name = 'Confusion Matrix - Accuracy ' + str(round(acc,2)) + \"%\"\n",
    "    ax.set_title(title_name,fontsize=20) \n",
    "    ax.xaxis.set_ticklabels(['Normal', 'Anomaly'],rotation=45)\n",
    "    ax.yaxis.set_ticklabels(['Normal', 'Anomaly'],rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save is True:\n",
    "        plt.savefig(title_name+'.jpg', format='jpg', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update labels\n",
    "feature = pd.read_csv('new_features.csv')\n",
    "east_data = pd.read_csv('new_west_data.csv')\n",
    "\n",
    "feature_day_cond = {}\n",
    "\n",
    "new_cond = []\n",
    "for i in feature.index:\n",
    "    feature_day_cond[str(int(feature.loc[i]['date']))] = int(feature.loc[i]['cond'])\n",
    "\n",
    "for j in east_data.index:\n",
    "    day = str(east_data.loc[j]['date_time'])\n",
    "    condition = east_data.loc[j]['condition']\n",
    "    \n",
    "    if day not in feature_day_cond:\n",
    "        new_cond.append(0)\n",
    "        continue\n",
    "    new_cond.append(feature_day_cond[day])\n",
    "    \n",
    "east_data['condition'] = new_cond\n",
    "export_csv = east_data.to_csv (\"new_west_data.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# feature = pd.read_csv('new_features.csv')\n",
    "east_data = pd.read_csv('new_west_data.csv')\n",
    "\n",
    "# Create object\n",
    "visual = helper.visualizer()\n",
    "model = helper.modeling()\n",
    "process = helper.data_processing()\n",
    "\n",
    "# Create daily raw data\n",
    "raw_data = process.mape_distribution(east_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "\n",
    "weather_collect = collections.Counter(east_data['weather']).most_common()\n",
    "weather_dict = {}\n",
    "for ith, weather_info in enumerate(weather_collect):\n",
    "    weather_dict[weather_info[0]] = ith\n",
    "\n",
    "feature_dict = {'date':[],'mse':[],'std':[],'corr':[],'max_power':[],'weather':[],'cond':[]}\n",
    "\n",
    "for day in raw_data:\n",
    "    \n",
    "    if len(raw_data[day]) < 20:\n",
    "        continue\n",
    "    \n",
    "    feature_dict['date'].append(day)\n",
    "    feature_dict['weather'].append(weather_dict[raw_data[day]['weather'].values[0]])\n",
    "    data = raw_data[day].drop(['weather','condition'],axis=1)\n",
    "    \n",
    "    # MSE and STD features\n",
    "    res,_ = model.model_predict(data)\n",
    "    feature_dict['mse'].append(np.mean(res))\n",
    "    feature_dict['std'].append(np.std(res))\n",
    "    \n",
    "    # Correlation feature\n",
    "    res = []\n",
    "    first = 'panel_1_power'\n",
    "    for col in data.columns:\n",
    "        if col != first:\n",
    "            res.append(pearsonr(data[col].values,data[first].values)[0])\n",
    "    \n",
    "    feature_dict['corr'].append(min(res))\n",
    "    \n",
    "    # Max power feature\n",
    "    power = []\n",
    "    for col in data.columns:\n",
    "        power.append(max(data[col]))\n",
    "    \n",
    "    feature_dict['max_power'].append(np.mean(power))\n",
    "    \n",
    "    # Condition\n",
    "    condition = east_data[east_data['date_time']==float(day)]['condition'].values[0]\n",
    "    feature_dict['cond'].append(condition)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88.16793893129771, 88.54961832061069, 85.38461538461539]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame()\n",
    "\n",
    "# for key,value in feature_dict.items():\n",
    "#     df[key] = value\n",
    "\n",
    "dataset = pd.read_csv('new_west_data.csv')   \n",
    "df = process.feature_generate(dataset)\n",
    "    \n",
    "score, cm, rf_model,X_test,y_test,test_date = random_forest_class(df.dropna())\n",
    "print(score)\n",
    "\n",
    "wrong_day = []\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    if y_test[i] != pred:\n",
    "        wrong_day.append(test_date[i]) \n",
    "        \n",
    "check_day = pd.DataFrame()\n",
    "for day in wrong_day:\n",
    "    check_day = pd.concat([check_day,df[df['date']==day]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = df.to_csv (\"new_features.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95.41984732824427, 92.72030651340997, 90.80459770114942]\n"
     ]
    }
   ],
   "source": [
    "feature = pd.read_csv('new_features.csv')\n",
    "\n",
    "score, cm, rf_model,X_test,y_test,test_date = random_forest_class(feature.dropna())\n",
    "print(score)\n",
    "\n",
    "wrong_day = []\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    if y_test[i] != pred:\n",
    "        wrong_day.append(test_date[i]) \n",
    "        \n",
    "check_day = pd.DataFrame()\n",
    "for day in wrong_day:\n",
    "    check_day = pd.concat([check_day,feature[feature['date']==day]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4735\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4736\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4737\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-3a4e860cf478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0merror_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcorr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'corr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cond'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4742\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4743\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4744\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4745\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4746\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mse'"
     ]
    }
   ],
   "source": [
    "for i in check_day.index:\n",
    "    error_ = round(check_day.loc[i]['mse'],5)\n",
    "    std_ = round(check_day.loc[i]['std'],5)\n",
    "    corr_ = round(check_day.loc[i]['corr'],5)\n",
    "    condition = check_day.loc[i]['cond']\n",
    "    day = str(int(check_day.loc[i]['date']))\n",
    "    data = raw_data[day].drop(['weather','condition'],axis=1)\n",
    "    \n",
    "    title ='Date: ' + str(day) + ' MSE: ' + str(error_) + ' STD: ' + str(std_) + ' Corr: ' + str(corr_) + ' Condition: ' + str(condition)\n",
    "    visual.raw_data_plot(data,title,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 196, 0: 6})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(feature[feature['corr']>=0.96]['cond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_day = dataset[dataset['weather']=='sunny'][dataset['condition']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
